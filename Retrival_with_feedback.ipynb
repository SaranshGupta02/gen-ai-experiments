{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System with Feedback Loop: Enhancing Retrieval and Response Quality\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
    "\n",
    "[![Build Fast with AI](https://img.shields.io/badge/BuildFastWithAI-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://www.buildfastwithai.com/genai-course)\n",
    "[![EduChain GitHub](https://img.shields.io/github/stars/satvik314/educhain?style=for-the-badge&logo=github&color=gold)](https://github.com/satvik314/educhain)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uNn0ojBJf4UxEfK8Q6ASOtQ8UXVKxSDv?usp=chrome_ntp)\n",
    "## Master Generative AI in 6 Weeks\n",
    "**What You'll Learn:**\n",
    "- Build with Latest LLMs\n",
    "- Create Custom AI Apps\n",
    "- Learn from Industry Experts\n",
    "- Join Innovation Community\n",
    "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
    "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
    "*Empowering the Next Generation of AI Innovators\n",
    "\n",
    "Method Overview\n",
    "System Initialization\n",
    "\n",
    "The system extracts content from PDFs to build a vector database for information storage.\n",
    "A retriever is configured to fetch relevant content from this vector database.\n",
    "A language model (LLM) is employed to generate responses based on the retrieved data.\n",
    "Query Handling\n",
    "\n",
    "When a user submits a query, the retriever identifies and fetches the most relevant documents.\n",
    "The LLM processes these documents to craft a response tailored to the query.\n",
    "Collecting Feedback\n",
    "\n",
    "Users provide feedback on the accuracy and quality of responses.\n",
    "This feedback is stored in a structured format, such as a JSON file, for future reference.\n",
    "Adjusting Relevance Scores\n",
    "\n",
    "For future queries, the system evaluates stored feedback to refine the document relevance scores.\n",
    "An LLM evaluates the feedback to determine its applicability to the current query.\n",
    "Documents are re-ranked based on the adjusted scores.\n",
    "Retriever Optimization\n",
    "\n",
    "The retriever is updated to prioritize documents based on the adjusted scores.\n",
    "This ensures that the system continuously improves its relevance for future queries.\n",
    "Index Fine-Tuning\n",
    "\n",
    "Periodically, the system fine-tunes the vector database.\n",
    "High-quality feedback is used to generate additional, refined documents.\n",
    "These new documents are incorporated into the vector database to further enhance retrieval accuracy.\n",
    "Key Advantages\n",
    "Continuous Learning: The system evolves by learning from each user interaction.\n",
    "Personalization: Feedback allows the system to adapt to specific user preferences.\n",
    "Improved Relevance: Responses become increasingly accurate over time due to iterative feedback integration.\n",
    "Quality Assurance: Repeated low-quality responses are minimized through relevance adjustments.\n",
    "Dynamic Adaptability: The system adjusts to changes in user needs and document contents.\n",
    "Summary\n",
    "This feedback-driven retrieval system enhances the traditional RAG (retrieval-augmented generation) pipeline by introducing a feedback loop that continuously refines the relevance of retrieved content. It is especially beneficial in domains requiring high accuracy and adaptability to evolving user requirements.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define documents path\n",
    "### Download from here https://drive.google.com/file/d/1F0XGihSvR_4L0MIDH3iz02X2Ce3UcRrD/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"path-to-your-file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "def read_pdf_to_string(path):\n",
    "    # Open the PDF document located at the specified path\n",
    "    doc = fitz.open(path)\n",
    "    content = \"\"\n",
    "    # Iterate over each page in the document\n",
    "    for page_num in range(len(doc)):\n",
    "        # Get the current page\n",
    "        page = doc[page_num]\n",
    "        # Extract the text content from the current page and append it to the content string\n",
    "        content += page.get_text()\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_from_string(content, chunk_size=1000, chunk_overlap=200):\n",
    "    \n",
    "    if not isinstance(chunk_overlap, int) or chunk_overlap < 0:\n",
    "        raise ValueError(\"chunk_overlap must be a non-negative integer.\")\n",
    "\n",
    "    try:\n",
    "        # Split the content into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False,\n",
    "        )\n",
    "        chunks = text_splitter.create_documents([content])\n",
    "\n",
    "        # Assign metadata to each chunk\n",
    "        for chunk in chunks:\n",
    "            chunk.metadata['relevance_score'] = 1.0\n",
    "\n",
    "        # Generate embeddings and create the vector store\n",
    "        embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"An error occurred during the encoding process: {str(e)}\")\n",
    "\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create vector store and retrieval QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = read_pdf_to_string(path)\n",
    "vectorstore = encode_from_string(content)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000,api_key=OPENAI_API_KEY)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feedback(query, response, relevance, quality, comments=\"\"):\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"relevance\": int(relevance),\n",
    "        \"quality\": int(quality),\n",
    "        \"comments\": comments\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_feedback(feedback):\n",
    "    with open(\"feedback_data.json\", \"a\") as f:\n",
    "        json.dump(feedback, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feedback_data():\n",
    "    feedback_data = []\n",
    "    try:\n",
    "        with open(\"feedback_data.json\", \"r\") as f:\n",
    "            for line in f:\n",
    "                feedback_data.append(json.loads(line.strip()))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No feedback data file found. Starting with empty feedback.\")\n",
    "    return feedback_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to adjust files relevancy based on the feedbacks file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    answer: str = Field(..., title=\"The answer to the question. The options can be only 'Yes' or 'No'\")\n",
    "\n",
    "def adjust_relevance_scores(query: str, docs: List[Any], feedback_data: List[Dict[str, Any]]) -> List[Any]:\n",
    "    # Create a prompt template for relevance checking\n",
    "    relevance_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"feedback_query\", \"doc_content\", \"feedback_response\"],\n",
    "        template=\"\"\"\n",
    "        Determine if the following feedback response is relevant to the current query and document content.\n",
    "        You are also provided with the Feedback original query that was used to generate the feedback response.\n",
    "        Current query: {query}\n",
    "        Feedback query: {feedback_query}\n",
    "        Document content: {doc_content}\n",
    "        Feedback response: {feedback_response}\n",
    "        \n",
    "        Is this feedback relevant? Respond with only 'Yes' or 'No'.\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000,api_key=OPENAI_API_KEY)\n",
    "\n",
    "    # Create an LLMChain for relevance checking\n",
    "    relevance_chain = relevance_prompt | llm\n",
    "\n",
    "    for doc in docs:\n",
    "        relevant_feedback = []\n",
    "        \n",
    "        for feedback in feedback_data:\n",
    "            # Use LLM to check relevance\n",
    "            input_data = {\n",
    "                \"query\": query,\n",
    "                \"feedback_query\": feedback['query'],\n",
    "                \"doc_content\": doc.page_content[:1000],\n",
    "                \"feedback_response\": feedback['response']\n",
    "            }\n",
    "            \n",
    "            result = relevance_chain.invoke(input_data).content\n",
    "        \n",
    "            if result.lower() == 'yes':\n",
    "            \n",
    "                relevant_feedback.append(feedback)\n",
    "        \n",
    "        # Adjust the relevance score based on feedback\n",
    "        if relevant_feedback:\n",
    "            avg_relevance = sum(f['relevance'] for f in relevant_feedback) / len(relevant_feedback)\n",
    "            doc.metadata['relevance_score'] *= (avg_relevance / 3)  # Assuming a 1-5 scale, 3 is neutral\n",
    "    \n",
    "    # Re-rank documents based on adjusted scores\n",
    "    return sorted(docs, key=lambda x: x.metadata['relevance_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fine tune the vector index to include also queries + answers that received good feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_index(feedback_data: List[Dict[str, Any]], texts: List[str]) -> Any:\n",
    "    # Filter high-quality responses\n",
    "    good_responses = [f for f in feedback_data if f['relevance'] >= 4 and f['quality'] >= 4]\n",
    "    \n",
    "    # Extract queries and responses, and create new documents\n",
    "    additional_texts = []\n",
    "    for f in good_responses:\n",
    "        combined_text = f['query'] + \" \" + f['response']\n",
    "        additional_texts.append(combined_text)\n",
    "\n",
    "    # make the list a string\n",
    "    additional_texts = \" \".join(additional_texts)\n",
    "    \n",
    "    # Create a new index with original and high-quality texts\n",
    "    all_texts = texts + additional_texts\n",
    "    new_vectorstore = encode_from_string(all_texts)\n",
    "    \n",
    "    return new_vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of how to retrieve answers with respect to user feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The greenhouse effect is a natural process where greenhouse gases in the Earth's atmosphere, such as carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O), trap heat from the sun. This trapped heat helps to keep the planet warm enough to support life. However, human activities have intensified this natural process by increasing the concentration of these gases in the atmosphere, leading to a warmer climate.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter relevance in output(out of 10):  3\n",
      "Enter quality in output (out of 10):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='642c992d-605c-4e4f-bd13-4ffd7a17a139', metadata={'relevance_score': 2.777777777777778}, page_content='The use of synthetic fertilizers in agriculture releases nitrous oxide, a potent greenhouse gas. \\nPractices such as precision farming and organic fertilizers can mitigate these emissions. The \\ndevelopment of eco-friendly fertilizers and farming techniques is essential for reducing the \\nagricultural sector\\'s carbon footprint. \\nChapter 3: Effects of Climate Change \\nThe effects of climate change are already being felt around the world and are projected to \\nintensify in the coming decades. These effects include: \\nRising Temperatures \\nGlobal temperatures have risen by about 1.2 degrees Celsius (2.2 degrees Fahrenheit) since \\nthe late 19th century. This warming is not uniform, with some regions experiencing more \\nsignificant increases than others. \\nHeatwaves \\nHeatwaves are becoming more frequent and severe, posing risks to human health, agriculture, \\nand infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect.'), Document(id='802fc814-3d73-48c8-8d3e-fe895f03ca1b', metadata={'relevance_score': 1.6666666666666667}, page_content='Chapter 2: Causes of Climate Change \\nGreenhouse Gases \\nThe primary cause of recent climate change is the increase in greenhouse gases in the \\natmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \\noxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \\nfor life on Earth, as it keeps the planet warm enough to support life. However, human \\nactivities have intensified this natural process, leading to a warmer climate. \\nFossil Fuels \\nBurning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \\nnatural gas used for electricity, heating, and transportation. The industrial revolution marked \\nthe beginning of a significant increase in fossil fuel consumption, which continues to rise \\ntoday. \\nCoal \\nCoal is the most carbon-intensive fossil fuel, and its use for electricity generation is a major \\nsource of CO2 emissions. Despite a decline in some regions, coal remains a significant'), Document(id='5b5c58ec-bef0-42c3-9718-d00f738aa63a', metadata={'relevance_score': 1.6666666666666667}, page_content='Heatwaves \\nHeatwaves are becoming more frequent and severe, posing risks to human health, agriculture, \\nand infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect. \\nHeatwaves can lead to heat-related illnesses and exacerbate existing health conditions. \\nChanging Seasons \\nClimate change is altering the timing and length of seasons, affecting ecosystems and human \\nactivities. For example, spring is arriving earlier, and winters are becoming shorter and \\nmilder in many regions. This shift disrupts plant and animal life cycles and agricultural \\npractices. \\nMelting Ice and Rising Sea Levels \\nWarmer temperatures are causing polar ice caps and glaciers to melt, contributing to rising \\nsea levels. Sea levels have risen by about 20 centimeters (8 inches) in the past century, \\nthreatening coastal communities and ecosystems. \\nPolar Ice Melt \\nThe Arctic is warming at more than twice the global average rate, leading to significant ice'), Document(id='063081dc-55e0-47d8-96d3-d723ba612e30', metadata={'relevance_score': 1.6666666666666667}, page_content='Natural Gas \\nNatural gas is the least carbon-intensive fossil fuel and is often seen as a \"bridge fuel\" to a \\nlower-carbon future. However, its extraction and use still contribute to greenhouse gas \\nemissions, particularly methane, which is a potent greenhouse gas. Innovations in fracking \\ntechnology have made natural gas more accessible, but this comes with environmental and \\nhealth concerns. \\nDeforestation \\nForests act as carbon sinks, absorbing CO2 from the atmosphere. When trees are cut down \\nfor timber or to clear land for agriculture, this stored carbon is released back into the \\natmosphere. Deforestation reduces the number of trees that can absorb CO2, exacerbating the \\ngreenhouse effect. \\nTropical Deforestation \\nTropical rainforests are particularly important for carbon storage. Deforestation in the \\nAmazon, Congo Basin, and Southeast Asia has significant impacts on global carbon cycles')]\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n",
      "Yes\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What is the greenhouse effect?\"\n",
    "\n",
    "# Get response from RAG system\n",
    "response = qa_chain(query)[\"result\"]\n",
    "print(response)\n",
    "relevance = int(input(\"Enter relevance in output(out of 10): \"))\n",
    "quality = int(input(\"Enter quality in output (out of 10): \"))\n",
    "\n",
    "# Collect feedback\n",
    "feedback = get_user_feedback(query, response, relevance, quality)\n",
    "\n",
    "# Store feedback\n",
    "store_feedback(feedback)\n",
    "\n",
    "# Adjust relevance scores for future retrievals\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "print(docs)\n",
    "adjusted_docs = adjust_relevance_scores(query, docs, load_feedback_data())\n",
    "\n",
    "# Update the retriever with adjusted docs\n",
    "retriever.search_kwargs['k'] = len(adjusted_docs)\n",
    "retriever.search_kwargs['docs'] = adjusted_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the vectorstore periodicly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Periodically (e.g., daily or weekly), fine-tune the index\n",
    "new_vectorstore = fine_tune_index(load_feedback_data(), content)\n",
    "retriever = new_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
