{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1wYSMgJtARFdvTt5g7E20mE4NmwUFUuog\" width=\"200\">\n",
        "\n",
        "[![Gen AI Experiments](https://img.shields.io/badge/Gen%20AI%20Experiments-GenAI%20Bootcamp-blue?style=for-the-badge&logo=artificial-intelligence)](https://github.com/buildfastwithai/gen-ai-experiments)\n",
        "[![Gen AI Experiments GitHub](https://img.shields.io/github/stars/buildfastwithai/gen-ai-experiments?style=for-the-badge&logo=github&color=gold)](http://github.com/buildfastwithai/gen-ai-experiments)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1rNwI_8GcF-9WG4wuzvvvv4KgMlZYNuX7?usp=sharing)\n",
        "\n",
        "## Master Generative AI in 8 Weeks\n",
        "**What You'll Learn:**\n",
        "- Master cutting-edge AI tools & frameworks\n",
        "- 6 weeks of hands-on, project-based learning\n",
        "- Weekly live mentorship sessions\n",
        "- No coding experience required\n",
        "- Join Innovation Community\n",
        "Transform your AI ideas into reality through hands-on projects and expert mentorship.\n",
        "[Start Your Journey](https://www.buildfastwithai.com/genai-course)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q7o8ooCkyApO"
      },
      "id": "q7o8ooCkyApO"
    },
    {
      "cell_type": "markdown",
      "id": "629f9db1",
      "metadata": {
        "id": "629f9db1"
      },
      "source": [
        "# üöÄ Using Baseten Inference for LLMs\n",
        "This notebook demonstrates how to use **Baseten Inference API** to run different Large Language Models (LLMs) with the familiar OpenAI client.\n",
        "\n",
        "Baseten Model APIs are built for production first, with extra ordinary performance and reliability. Baseten Provides OpenAI compatible SDK, Pre-optimized performance, secure ans very scaleable Inference."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67fa2f68",
      "metadata": {
        "id": "67fa2f68"
      },
      "source": [
        "## üîß Setup\n",
        "Before starting, install the required library and set up your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6bd244",
      "metadata": {
        "id": "5b6bd244"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59b170d5",
      "metadata": {
        "id": "59b170d5"
      },
      "source": [
        "## ‚öôÔ∏è Initialize Client\n",
        "Replace the `api_key` with your own key from Baseten. We'll use `moonshotai/Kimi-K2-Instruct` as the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d4ba3b",
      "metadata": {
        "id": "25d4ba3b"
      },
      "outputs": [],
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Initialize client with Baseten endpoint\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get('BASETEN_API_KEY'),  # Setup your Baseten key in Secrets\n",
        "    base_url=\"https://inference.baseten.co/v1\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7bf939",
      "metadata": {
        "id": "7b7bf939"
      },
      "source": [
        "## ‚ú® Use Case 1: Hello World in Python\n",
        "Let's start with a simple prompt asking the model to generate a Hello World program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89851c10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89851c10",
        "outputId": "1fdfe50b-d5b6-4a0f-9df2-2039c4955182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "# hello_world.py\n",
            "\n",
            "def main():\n",
            "    print(\"Hello, World!\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"moonshotai/Kimi-K2-Instruct\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a Hello World program in Python\"}],\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c24f36c",
      "metadata": {
        "id": "4c24f36c"
      },
      "source": [
        "## ‚ú® Use Case 2: Text Summarization\n",
        "We can ask the model to summarize a piece of text into a short paragraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a858b21d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a858b21d",
        "outputId": "f5b763d2-6ac4-4c0f-a1f9-ae92d2870a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is revolutionizing technology interactions, enhancing efficiency and decision-making across industries through applications like natural language processing and computer vision.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "long_text = \"\"\"Artificial Intelligence is transforming the way we interact with technology.\n",
        "From natural language processing to computer vision, AI models are being applied\n",
        "across industries to improve efficiency, accuracy, and decision-making.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"moonshotai/Kimi-K2-Instruct\",\n",
        "    messages=[{\"role\": \"user\", \"content\": f\"Summarize the following text:\\n{long_text}\"}],\n",
        "    max_tokens=150\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed88151",
      "metadata": {
        "id": "9ed88151"
      },
      "source": [
        "## ‚ú® Use Case 3: Creative Writing\n",
        "Finally, let‚Äôs generate a short creative story using the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6616bbde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6616bbde",
        "outputId": "49561180-9ef7-40a3-af32-513a10014c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Red Horizon**  \n",
            "*Sol 1,247, Ares Calendar*\n",
            "\n",
            "The dust storm had been raging for six days when the sky finally cleared, revealing the twin moons of Mars hanging like pale lanterns above the Valles Marineris. Dr. Lila Moreau pressed her gloved hand against the viewport of Hab-3, watching the last red clouds unravel into nothing. Somewhere out there, beneath the regolith, the *Ariadne* was waiting‚Äîan alien artifact no human had yet managed to wake.\n",
            "\n",
            "‚ÄúStorm‚Äôs over,‚Äù she said into the comm. ‚ÄúTime to dig.‚Äù\n",
            "\n",
            "The response crackled back from the rover: ‚ÄúCopy that, Doc. Bringing the coffee.‚Äù\n",
            "\n",
            "Lila smiled despite herself. Coffee on Mars was a ritual, a tether to Earth. She sealed her helmet and stepped into the airlock, boots clanking against the grated floor. Outside, the temperature was -80¬∞C, but her suit kept her warm. The horizon\n"
          ]
        }
      ],
      "source": [
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"moonshotai/Kimi-K2-Instruct\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a short science fiction story about humans living on Mars.\"}],\n",
        "    max_tokens=200,\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0312861",
      "metadata": {
        "id": "e0312861"
      },
      "source": [
        "## ‚úÖ Wrap-Up\n",
        "In this notebook, we explored how to:\n",
        "- Connect to Baseten Inference with the OpenAI client\n",
        "- Run prompts for code generation, summarization, and creative writing\n",
        "\n",
        "You can extend these examples to build chatbots, assistants, or custom LLM apps!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}